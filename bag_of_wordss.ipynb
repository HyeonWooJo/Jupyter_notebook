{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer,\\\n",
    "WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/labeledTrainData.tsv', delimiter='\\t')\n",
    "df2 = pd.read_csv('data/imdb_master.csv', encoding='latin-1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['Unnamed: 0', 'type', 'file'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsup    50000\n",
       "pos      25000\n",
       "neg      25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df2[df2.sentiment != 'unsup']\n",
    "df2['sentiment'] = df2['sentiment'].map({'pos':1, 'neg':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      Once again Mr. Costner has dragged out a movie...          0\n",
       "1      This is an example of why the majority of acti...          0\n",
       "2      First of all I hate those moronic rappers, who...          0\n",
       "3      Not even the Beatles could write songs everyon...          0\n",
       "4      Brass pictures (movies is not a fitting word f...          0\n",
       "...                                                  ...        ...\n",
       "49995  Seeing as the vote average was pretty low, and...          1\n",
       "49996  The plot had some wretched, unbelievable twist...          1\n",
       "49997  I am amazed at how this movie(and most others ...          1\n",
       "49998  A Christmas Together actually came before my t...          1\n",
       "49999  Working-class romantic drama from director Mar...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  With all this stuff going down at the moment w...\n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2          0  The film starts with a manager (Nicholas Bell)...\n",
       "3          0  It must be assumed that those who praised this...\n",
       "4          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  75000 non-null  int64 \n",
      " 1   review     75000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def clean_text(raw_review):\n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "    \n",
    "    letters_only = re.sub('[^a-zA-z]', ' ', review_text)\n",
    "    \n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    meangingful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    stemming_words = [stemmer.stem(w) for w in meangingful_words]\n",
    "    \n",
    "    return (' '.join(stemming_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_review'] = df['review'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.05728"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Processed_review.apply(lambda x: len(x.split(' '))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_reviews = df['Processed_review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_reviews = df['review'].size\n",
    "\n",
    "# clean_train_reviews = []\n",
    "\n",
    "# for i in range(num_reviews):\n",
    "#     clean_train_reviews.append(clean_text(df['review'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, \n",
    "# which is scikit-learn's bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer='word',\n",
    "                            tokenizer=None,\n",
    "                            preprocessor=None,\n",
    "                            stop_words=None,\n",
    "                            max_features=5000)\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of\n",
    "# strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('vect', vectorizer),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.21 s, sys: 225 ms, total: 5.44 s\n",
      "Wall time: 5.44 s\n",
      "(75000, 5000)\n"
     ]
    }
   ],
   "source": [
    "%time train_data_features=pipeline.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaron',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'abduct',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'abomin',\n",
       " 'abort',\n",
       " 'abound',\n",
       " 'abraham',\n",
       " 'abrupt',\n",
       " 'absenc',\n",
       " 'absent',\n",
       " 'absolut',\n",
       " 'absorb',\n",
       " 'absurd',\n",
       " 'abund',\n",
       " 'abus',\n",
       " 'abysm',\n",
       " 'academi',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'acclaim',\n",
       " 'accompani',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'accus',\n",
       " 'ace',\n",
       " 'achiev',\n",
       " 'acid',\n",
       " 'acknowledg',\n",
       " 'acquaint',\n",
       " 'acquir',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adequ',\n",
       " 'adjust',\n",
       " 'admir',\n",
       " 'admit',\n",
       " 'adolesc',\n",
       " 'adopt',\n",
       " 'ador',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'adventur',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'aesthet',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affleck',\n",
       " 'afford',\n",
       " 'aforement',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggress',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aimless',\n",
       " 'air',\n",
       " 'airplan',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'akshay',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alec',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexand',\n",
       " 'alfr',\n",
       " 'ali',\n",
       " 'alic',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alik',\n",
       " 'alison',\n",
       " 'aliv',\n",
       " 'alleg',\n",
       " 'allen',\n",
       " 'alley',\n",
       " 'alli',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alongsid',\n",
       " 'alreadi',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'altman',\n",
       " 'altogeth',\n",
       " 'alvin',\n",
       " 'alway',\n",
       " 'amanda',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amaz',\n",
       " 'amazon',\n",
       " 'ambigu',\n",
       " 'ambit',\n",
       " 'ambiti',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amitabh',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amount',\n",
       " 'amus',\n",
       " 'analysi',\n",
       " 'analyz',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'anderson',\n",
       " 'andi',\n",
       " 'andr',\n",
       " 'andrew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'anger',\n",
       " 'angl',\n",
       " 'angri',\n",
       " 'angst',\n",
       " 'anim',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'anni',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antagonist',\n",
       " 'antholog',\n",
       " 'anthoni',\n",
       " 'anti',\n",
       " 'antic',\n",
       " 'anticip',\n",
       " 'antonio',\n",
       " 'antonioni',\n",
       " 'antwon',\n",
       " 'anxious',\n",
       " 'anybodi',\n",
       " 'anyhow',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'apart',\n",
       " 'ape',\n",
       " 'apocalyps',\n",
       " 'apocalypt',\n",
       " 'apolog',\n",
       " 'appal',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appl',\n",
       " 'applaud',\n",
       " 'appli',\n",
       " 'appreci',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'arab',\n",
       " 'arc',\n",
       " 'archiv',\n",
       " 'area',\n",
       " 'argento',\n",
       " 'argu',\n",
       " 'arguabl',\n",
       " 'argument',\n",
       " 'aris',\n",
       " 'aristocrat',\n",
       " 'arm',\n",
       " 'armi',\n",
       " 'armstrong',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arrang',\n",
       " 'arrest',\n",
       " 'arriv',\n",
       " 'arrog',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'articl',\n",
       " 'artifici',\n",
       " 'artist',\n",
       " 'artsi',\n",
       " 'artwork',\n",
       " 'ash',\n",
       " 'asham',\n",
       " 'ashley',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asid',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspir',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assault',\n",
       " 'assembl',\n",
       " 'assert',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assort',\n",
       " 'assum',\n",
       " 'assur',\n",
       " 'astair',\n",
       " 'astonish',\n",
       " 'astound',\n",
       " 'astronaut',\n",
       " 'asylum',\n",
       " 'athlet',\n",
       " 'atlanti',\n",
       " 'atmospher',\n",
       " 'atom',\n",
       " 'atroc',\n",
       " 'atroci',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'audienc',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aussi',\n",
       " 'austen',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'authent',\n",
       " 'author',\n",
       " 'automat',\n",
       " 'avail',\n",
       " 'aveng',\n",
       " 'averag',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awak',\n",
       " 'awaken',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesom',\n",
       " 'awhil',\n",
       " 'awkward',\n",
       " 'axe',\n",
       " 'babe',\n",
       " 'babi',\n",
       " 'bacal',\n",
       " 'back',\n",
       " 'backdrop',\n",
       " 'background',\n",
       " 'backward',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'baddi',\n",
       " 'baffl',\n",
       " 'bag',\n",
       " 'bait',\n",
       " 'bake',\n",
       " 'baker',\n",
       " 'bakshi',\n",
       " 'balanc',\n",
       " 'baldwin',\n",
       " 'ball',\n",
       " 'ballet',\n",
       " 'bam',\n",
       " 'ban',\n",
       " 'banal',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'banter',\n",
       " 'bar',\n",
       " 'barbara',\n",
       " 'bare',\n",
       " 'bargain',\n",
       " 'barker',\n",
       " 'barn',\n",
       " 'barney',\n",
       " 'barrel',\n",
       " 'barri',\n",
       " 'barrymor',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basing',\n",
       " 'basketbal',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'bate',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battl',\n",
       " 'bay',\n",
       " 'bbc',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beatl',\n",
       " 'beatti',\n",
       " 'beauti',\n",
       " 'becam',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'beer',\n",
       " 'befriend',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'behav',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'bela',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'bell',\n",
       " 'belli',\n",
       " 'belong',\n",
       " 'belov',\n",
       " 'belt',\n",
       " 'belushi',\n",
       " 'ben',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'bent',\n",
       " 'bergman',\n",
       " 'berlin',\n",
       " 'bernard',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'betray',\n",
       " 'bett',\n",
       " 'better',\n",
       " 'betti',\n",
       " 'bever',\n",
       " 'bewar',\n",
       " 'beyond',\n",
       " 'bias',\n",
       " 'bibl',\n",
       " 'biblic',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'biker',\n",
       " 'bikini',\n",
       " 'biko',\n",
       " 'bill',\n",
       " 'billi',\n",
       " 'bin',\n",
       " 'biographi',\n",
       " 'biopic',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bitten',\n",
       " 'bitter',\n",
       " 'bizarr',\n",
       " 'black',\n",
       " 'blackmail',\n",
       " 'blade',\n",
       " 'blah',\n",
       " 'blair',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'bland',\n",
       " 'blank',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'bleak',\n",
       " 'bleed',\n",
       " 'blend',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blink',\n",
       " 'blob',\n",
       " 'block',\n",
       " 'blockbust',\n",
       " 'blond',\n",
       " 'blood',\n",
       " 'bloodi',\n",
       " 'bloom',\n",
       " 'blow',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'blunt',\n",
       " 'blur',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boast',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bobbi',\n",
       " 'bodi',\n",
       " 'bogart',\n",
       " 'boil',\n",
       " 'bold',\n",
       " 'boll',\n",
       " 'bollywood',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bonni',\n",
       " 'bonus',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'boom',\n",
       " 'boot',\n",
       " 'booth',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'boredom',\n",
       " 'bori',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bother',\n",
       " 'bottl',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bounc',\n",
       " 'bound',\n",
       " 'bounti',\n",
       " 'bourn',\n",
       " 'bow',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxer',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boyl',\n",
       " 'brad',\n",
       " 'bradi',\n",
       " 'brain',\n",
       " 'brainless',\n",
       " 'branagh',\n",
       " 'brand',\n",
       " 'brando',\n",
       " 'brat',\n",
       " 'brave',\n",
       " 'bravo',\n",
       " 'brazil',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathtak',\n",
       " 'breed',\n",
       " 'brenda',\n",
       " 'brian',\n",
       " 'brick',\n",
       " 'bride',\n",
       " 'bridg',\n",
       " 'bridget',\n",
       " 'brief',\n",
       " 'briefli',\n",
       " 'bright',\n",
       " 'brillianc',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'brit',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broadway',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'bronson',\n",
       " 'brood',\n",
       " 'brook',\n",
       " 'brooklyn',\n",
       " 'bros',\n",
       " 'brosnan',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruce',\n",
       " 'bruno',\n",
       " 'brush',\n",
       " 'brutal',\n",
       " 'btw',\n",
       " 'bubbl',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'bud',\n",
       " 'buddi',\n",
       " 'budget',\n",
       " 'buff',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bulk',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bulli',\n",
       " 'bullock',\n",
       " 'bumbl',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'bunni',\n",
       " 'buri',\n",
       " 'burn',\n",
       " 'burst',\n",
       " 'burt',\n",
       " 'burton',\n",
       " 'bus',\n",
       " 'busey',\n",
       " 'bush',\n",
       " 'busi',\n",
       " 'businessman',\n",
       " 'bust',\n",
       " 'buster',\n",
       " 'butcher',\n",
       " 'butler',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buzz',\n",
       " 'bye',\n",
       " 'cabin',\n",
       " 'cabl',\n",
       " 'cage',\n",
       " 'cagney',\n",
       " 'cain',\n",
       " 'cake',\n",
       " 'calib',\n",
       " 'california',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'camcord',\n",
       " 'came',\n",
       " 'cameo',\n",
       " 'camera',\n",
       " 'cameron',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'campbel',\n",
       " 'campi',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candi',\n",
       " 'candid',\n",
       " 'candl',\n",
       " 'cann',\n",
       " 'cannib',\n",
       " 'cannon',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'canyon',\n",
       " 'cap',\n",
       " 'capabl',\n",
       " 'caper',\n",
       " 'capit',\n",
       " 'captain',\n",
       " 'captiv',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardboard',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carel',\n",
       " 'carey',\n",
       " 'cari',\n",
       " 'caricatur',\n",
       " 'carl',\n",
       " 'carla',\n",
       " 'carlo',\n",
       " 'carmen',\n",
       " 'carol',\n",
       " 'carpent',\n",
       " 'carradin',\n",
       " 'carrey',\n",
       " 'carri',\n",
       " 'carter',\n",
       " 'cartoon',\n",
       " 'cartoonish',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'casino',\n",
       " 'cassavet',\n",
       " 'cassidi',\n",
       " 'cast',\n",
       " 'castl',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catchi',\n",
       " 'categori',\n",
       " 'catherin',\n",
       " 'cathol',\n",
       " 'cattl',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'cave',\n",
       " 'cbs',\n",
       " 'cd',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'celluloid',\n",
       " 'cemeteri',\n",
       " 'censor',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'central',\n",
       " 'centuri',\n",
       " 'cerebr',\n",
       " 'ceremoni',\n",
       " 'certain',\n",
       " 'cg',\n",
       " 'cgi',\n",
       " 'chain',\n",
       " 'chainsaw',\n",
       " 'chair',\n",
       " 'challeng',\n",
       " 'champion',\n",
       " 'championship',\n",
       " 'chan',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'channel',\n",
       " 'chao',\n",
       " 'chaplin',\n",
       " 'chapter',\n",
       " 'charact',\n",
       " 'character',\n",
       " 'characteris',\n",
       " 'characterist',\n",
       " 'charg',\n",
       " 'charisma',\n",
       " 'charismat',\n",
       " 'charl',\n",
       " 'charli',\n",
       " 'charlott',\n",
       " 'charm',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'che',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'cheek',\n",
       " 'cheer',\n",
       " 'chees',\n",
       " 'cheesi',\n",
       " 'chemistri',\n",
       " 'chess',\n",
       " 'chest',\n",
       " 'chew',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'childish',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'chines',\n",
       " 'chip',\n",
       " 'choic',\n",
       " 'choke',\n",
       " 'choos',\n",
       " 'chop',\n",
       " 'choppi',\n",
       " 'choreograph',\n",
       " 'choreographi',\n",
       " 'chorus',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christi',\n",
       " 'christian',\n",
       " 'christin',\n",
       " 'christina',\n",
       " 'christma',\n",
       " 'christoph',\n",
       " 'chronicl',\n",
       " 'chuck',\n",
       " 'chuckl',\n",
       " 'church',\n",
       " 'churn',\n",
       " 'cia',\n",
       " 'cigarett',\n",
       " 'cinderella',\n",
       " 'cinema',\n",
       " 'cinemat',\n",
       " 'cinematograph',\n",
       " 'cinematographi',\n",
       " 'circl',\n",
       " 'circumst',\n",
       " 'circus',\n",
       " 'citi',\n",
       " 'citizen',\n",
       " 'civil',\n",
       " 'civilian',\n",
       " 'clad',\n",
       " 'claim',\n",
       " 'clair',\n",
       " 'clan',\n",
       " 'clark',\n",
       " 'clash',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'claud',\n",
       " 'claus',\n",
       " 'claustrophob',\n",
       " 'claw',\n",
       " 'clay',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clerk',\n",
       " 'clever',\n",
       " 'clich',\n",
       " 'click',\n",
       " 'client',\n",
       " 'cliff',\n",
       " 'climact',\n",
       " 'climat',\n",
       " 'climax',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'clint',\n",
       " 'clip',\n",
       " 'clive',\n",
       " 'clock',\n",
       " 'clone',\n",
       " 'clooney',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closet',\n",
       " 'cloth',\n",
       " 'cloud',\n",
       " 'clown',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'clueless',\n",
       " 'clumsi',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coast',\n",
       " 'coaster',\n",
       " 'coat',\n",
       " 'code',\n",
       " 'coffe',\n",
       " 'coffin',\n",
       " 'cohen',\n",
       " 'coher',\n",
       " 'cohes',\n",
       " 'coincid',\n",
       " 'coke',\n",
       " 'cold',\n",
       " 'cole',\n",
       " 'colin',\n",
       " 'collabor',\n",
       " 'collaps',\n",
       " 'colleagu',\n",
       " 'collect',\n",
       " 'collector',\n",
       " 'colleg',\n",
       " 'colonel',\n",
       " 'coloni',\n",
       " 'color',\n",
       " 'colour',\n",
       " 'columbia',\n",
       " 'columbo',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combin',\n",
       " 'come',\n",
       " 'comeback',\n",
       " 'comed',\n",
       " 'comedi',\n",
       " 'comedian',\n",
       " 'comfort',\n",
       " 'comic',\n",
       " 'command',\n",
       " 'commend',\n",
       " 'comment',\n",
       " 'commentari',\n",
       " 'commerci',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'communic',\n",
       " 'communist',\n",
       " 'communiti',\n",
       " 'compani',\n",
       " 'companion',\n",
       " 'compar',\n",
       " 'comparison',\n",
       " 'compass',\n",
       " 'compel',\n",
       " 'compens',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'complic',\n",
       " 'compliment',\n",
       " 'compos',\n",
       " 'composit',\n",
       " 'comprehend',\n",
       " 'comprehens',\n",
       " 'compris',\n",
       " 'compromis',\n",
       " 'comput',\n",
       " 'con',\n",
       " 'conan',\n",
       " 'conceiv',\n",
       " 'concentr',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concert',\n",
       " 'conclud',\n",
       " 'conclus',\n",
       " 'condemn',\n",
       " 'condit',\n",
       " 'conduct',\n",
       " 'confess',\n",
       " 'confid',\n",
       " 'confin',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'confront',\n",
       " 'confus',\n",
       " 'congratul',\n",
       " 'connect',\n",
       " 'conneri',\n",
       " 'connor',\n",
       " 'conquer',\n",
       " 'conrad',\n",
       " 'conscienc',\n",
       " 'conscious',\n",
       " 'consequ',\n",
       " 'conserv',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'conspiraci',\n",
       " 'constant',\n",
       " 'constitut',\n",
       " 'construct',\n",
       " 'consum',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'contempl',\n",
       " 'contemporari',\n",
       " 'contempt',\n",
       " 'contend',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'context',\n",
       " 'continu',\n",
       " 'contract',\n",
       " 'contradict',\n",
       " 'contrari',\n",
       " 'contrast',\n",
       " 'contribut',\n",
       " 'contriv',\n",
       " 'control',\n",
       " 'controversi',\n",
       " 'conveni',\n",
       " 'convent',\n",
       " 'convers',\n",
       " 'convert',\n",
       " 'convey',\n",
       " 'convict',\n",
       " 'convinc',\n",
       " 'convolut',\n",
       " 'cook',\n",
       " 'cooki',\n",
       " 'cool',\n",
       " 'cooper',\n",
       " 'cop',\n",
       " 'cope',\n",
       " 'copi',\n",
       " 'coppola',\n",
       " 'core',\n",
       " 'corey',\n",
       " 'corman',\n",
       " 'corn',\n",
       " 'corner',\n",
       " 'corni',\n",
       " 'corpor',\n",
       " 'corps',\n",
       " 'correct',\n",
       " 'corrupt',\n",
       " 'cost',\n",
       " 'costum',\n",
       " 'couch',\n",
       " 'could',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counterpart',\n",
       " 'counti',\n",
       " 'countless',\n",
       " 'countri',\n",
       " 'countrysid',\n",
       " 'coup',\n",
       " 'coupl',\n",
       " 'courag',\n",
       " 'cours',\n",
       " 'court',\n",
       " ...]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 225  844  343 ... 3360  470  223]] aaron\n"
     ]
    }
   ],
   "source": [
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train feature 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 20s, sys: 1.59 s, total: 8min 21s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "%time forest = forest.fit(train_data_features, df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# %time np.mean(cross_val_score(forest, train_data_features, \\\n",
    "#                               df['sentiment'], cv=10, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/testData.tsv', delimiter='\\t')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_reviews = test['review'].apply(lambda x: clean_text(x)).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 s, sys: 22 ms, total: 1.89 s\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%time test_data_features = pipeline.transform(clean_test_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2043716 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment\n",
       "0  12311_10          1\n",
       "1    8348_2          0\n",
       "2    5828_4          0\n",
       "3    7186_2          0\n",
       "4   12128_7          1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('data/prac2.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
